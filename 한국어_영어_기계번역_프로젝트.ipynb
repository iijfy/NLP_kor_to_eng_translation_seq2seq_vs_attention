{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ‡°ğŸ‡·ğŸ‡ºğŸ‡¸ í•œêµ­ì–´ â†’ ì˜ì–´ ê¸°ê³„ë²ˆì—­ í”„ë¡œì íŠ¸\n",
        "í•œêµ­ì–´ ë¬¸ì¥ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” NMT ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ê³  ë¹„êµí•œë‹¤.\n",
        "\n",
        "êµ¬í˜„í•œ ëª¨ë¸\n",
        "1) ê¸°ë³¸ Seq2Seq (GRU Encoder-Decoder, Attention ì—†ìŒ)\n",
        "2) Seq2Seq + Bahdanau Attention (+ SentencePiece í† í¬ë‚˜ì´ì§•)\n",
        "\n",
        "í‰ê°€ ë°©ë²•\n",
        "- ìƒ˜í”Œ ë²ˆì—­ ì¶œë ¥(ì •ì„± í‰ê°€)\n",
        "- BLEU ì ìˆ˜(ì •ëŸ‰ í‰ê°€)\n"
      ],
      "metadata": {
        "id": "hs4WeY7BtL87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ í™˜ê²½ì„¤ì¹˜ & ì„í¬íŠ¸"
      ],
      "metadata": {
        "id": "vJ0J3gShtcOS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knoEHOUBQvhM"
      },
      "outputs": [],
      "source": [
        "# sentencepiece: ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì € í•™ìŠµ/ì‚¬ìš©\n",
        "# nltk: í† í°í™” ë° BLEU ê³„ì‚°ì— ì‚¬ìš© ê°€ëŠ¥\n",
        "# sacrebleu: BLEU ê³„ì‚°ì„ ì¢€ ë” ì•ˆì •ì ìœ¼ë¡œ í•˜ê³  ì‹¶ì„ ë•Œ ì˜µì…˜\n",
        "\n",
        "!pip -q install sentencepiece nltk sacrebleu\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "# BLEU ê³„ì‚°ìš© (nltk or sacrebleu ì¤‘ì— ì„ íƒê°€ëŠ¥)\n",
        "import sacrebleu\n",
        "\n",
        "# ì¬í˜„ì„±: ê°™ì€ ëœë¤ ì‹œë“œë©´ ê²°ê³¼ê°€ \"ë¹„ìŠ·í•˜ê²Œ\" ë‚˜ì˜¤ë„ë¡ 42ë¡œ ê³ ì •\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ êµ¬ê¸€ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ + ê²½ë¡œ ì„¤ì •"
      ],
      "metadata": {
        "id": "3z76uAS4txY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/ì¼ìƒìƒí™œë°êµ¬ì–´ì²´_í•œì˜\"\n",
        "\n",
        "TRAIN_PATH = os.path.join(DATA_DIR, \"ì¼ìƒìƒí™œë°êµ¬ì–´ì²´_í•œì˜_train_set.json\")\n",
        "VALID_PATH = os.path.join(DATA_DIR, \"ì¼ìƒìƒí™œë°êµ¬ì–´ì²´_í•œì˜_valid_set.json\")\n",
        "\n",
        "print(\"TRAIN_PATH:\", TRAIN_PATH)\n",
        "print(\"VALID_PATH:\", VALID_PATH)\n",
        "print(\"exists(train)?\", os.path.exists(TRAIN_PATH))\n",
        "print(\"exists(valid)?\", os.path.exists(VALID_PATH))\n"
      ],
      "metadata": {
        "id": "IvI7uKOHtzxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ ë°ì´í„° ë¡œë“œ ì„¤ëª…\n",
        "- JSON íŒŒì¼ì€ íŒŒì´ì¬ì—ì„œ ë°”ë¡œ í•™ìŠµì— ëª» ì“°ê³ ,(í•œêµ­ì–´ ë¬¸ì¥, ì˜ì–´ ë¬¸ì¥) ìŒ í˜•íƒœë¡œ ì •ë¦¬í•´ì•¼ í•œë‹¤.\n",
        "\n",
        "ê·¸ë˜ì„œ:\n",
        "- JSONì„ ì½ì–´ì„œ\n",
        "- (\"ko\", \"mt\") í‚¤ë¥¼ êº¼ë‚´ê³ \n",
        "- (ko_sentence, en_sentence) ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“ ë‹¤\n"
      ],
      "metadata": {
        "id": "dhqsqwBIujec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_pairs(path: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    ì™œ í•¨ìˆ˜ë¡œ ë§Œë“¤ê¹Œ?\n",
        "    - ê°™ì€ ë¡œì§ì„ train/validì— ë°˜ë³µ ì ìš©í•´ì•¼ í•œë‹¤\n",
        "    - í•¨ìˆ˜ë¡œ ë§Œë“¤ë©´ 'ì¬ì‚¬ìš©' + 'ì‹¤ìˆ˜ ê°ì†Œ'\n",
        "\n",
        "    ë°˜í™˜ê°’:\n",
        "    - [(koë¬¸ì¥, enë¬¸ì¥), (koë¬¸ì¥, enë¬¸ì¥), ...]\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    pairs = []\n",
        "    for item in data:\n",
        "        ko = item[\"ko\"].strip()\n",
        "        en = item[\"mt\"].strip()\n",
        "        pairs.append((ko, en))\n",
        "    return pairs\n",
        "\n",
        "train_pairs = load_json_pairs(TRAIN_PATH)\n",
        "valid_pairs = load_json_pairs(VALID_PATH)\n",
        "\n",
        "print(\"train size:\", len(train_pairs))\n",
        "print(\"valid size:\", len(valid_pairs))\n",
        "print(\"\\nìƒ˜í”Œ 1ê°œ:\")\n",
        "print(\"KO:\", train_pairs[0][0])\n",
        "print(\"EN:\", train_pairs[0][1])\n"
      ],
      "metadata": {
        "id": "CcFoi-DNur1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ SentencePiece í•™ìŠµ(í† í¬ë‚˜ì´ì €)\n",
        "- ë‹¨ì–´ ê¸°ë°˜ í† í°í™”ëŠ” OOV(ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´)ì— ì·¨ì•½í•˜ë‹¤.\n",
        "SentencePieceëŠ” \"ì„œë¸Œì›Œë“œ\" ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ OOVë¥¼ ì¤„ì—¬ì¤€ë‹¤.\n",
        "\n",
        "ì´ë²ˆ ì‹¤í—˜ì€\n",
        "- vocab_size = 8000\n",
        "- model_type = unigram\n",
        "- pad_id=0, bos_id=1, eos_id=2, unk_id=3\n"
      ],
      "metadata": {
        "id": "m22RPNm_uyNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPM_DIR = os.path.join(DATA_DIR, \"spm_models\")\n",
        "os.makedirs(SPM_DIR, exist_ok=True)\n",
        "\n",
        "KO_CORPUS = os.path.join(SPM_DIR, \"train_ko.txt\")\n",
        "EN_CORPUS = os.path.join(SPM_DIR, \"train_en.txt\")\n",
        "\n",
        "KO_MODEL_PREFIX = os.path.join(SPM_DIR, \"spm_ko\")\n",
        "EN_MODEL_PREFIX = os.path.join(SPM_DIR, \"spm_en\")\n",
        "\n",
        "KO_MODEL_PATH = KO_MODEL_PREFIX + \".model\"\n",
        "EN_MODEL_PATH = EN_MODEL_PREFIX + \".model\"\n",
        "\n",
        "def write_corpus(pairs: List[Tuple[str, str]], ko_path: str, en_path: str):\n",
        "    \"\"\"\n",
        "    SentencePieceTrainerëŠ” 'í…ìŠ¤íŠ¸ íŒŒì¼'ì„ inputìœ¼ë¡œ ë°›ëŠ”ë‹¤.\n",
        "    ê·¸ë˜ì„œ JSON â†’ í…ìŠ¤íŠ¸ íŒŒì¼(í•œ ì¤„ì— í•œ ë¬¸ì¥)ë¡œ ë³€í™˜ì´ í•„ìš”í•˜ë‹¤.\n",
        "    \"\"\"\n",
        "    with open(ko_path, \"w\", encoding=\"utf-8\") as fko, open(en_path, \"w\", encoding=\"utf-8\") as fen:\n",
        "        for ko, en in pairs:\n",
        "            fko.write(ko.replace(\"\\n\", \" \") + \"\\n\")\n",
        "            fen.write(en.replace(\"\\n\", \" \") + \"\\n\")\n",
        "\n",
        "# ë§ë­‰ì¹˜ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±\n",
        "if (not os.path.exists(KO_CORPUS)) or (not os.path.exists(EN_CORPUS)):\n",
        "    write_corpus(train_pairs, KO_CORPUS, EN_CORPUS)\n",
        "    print(\"corpus files created\")\n",
        "\n",
        "def train_spm_if_needed(corpus_path: str, model_prefix: str, vocab_size: int = 8000):\n",
        "    \"\"\"\n",
        "    ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í•™ìŠµí•˜ê³ , ìˆìœ¼ë©´ ë„˜ì–´ê°„ë‹¤.\n",
        "    (Colab ì¬ì‹¤í–‰í•  ë•Œ ë§¤ë²ˆ í•™ìŠµí•˜ë©´ ì‹œê°„ ë‚­ë¹„ë¼ì„œ)\n",
        "    \"\"\"\n",
        "    model_path = model_prefix + \".model\"\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"skip training:\", model_path)\n",
        "        return\n",
        "\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=corpus_path,\n",
        "        model_prefix=model_prefix,\n",
        "        vocab_size=vocab_size,\n",
        "        model_type=\"unigram\",\n",
        "        character_coverage=1.0,\n",
        "        pad_id=0, unk_id=3, bos_id=1, eos_id=2,\n",
        "        # user_defined_symbolsëŠ” \"ë¬¸ìì—´ ì‹¬ë³¼\"ìš©ì¸ë°,\n",
        "        # ì—¬ê¸°ì„œëŠ” idë¥¼ ëª…í™•íˆ ì§€ì •í–ˆìœ¼ë‹ˆ í•„ìˆ˜ëŠ” ì•„ë‹˜.\n",
        "    )\n",
        "    print(\"trained:\", model_path)\n",
        "\n",
        "train_spm_if_needed(KO_CORPUS, KO_MODEL_PREFIX, vocab_size=8000)\n",
        "train_spm_if_needed(EN_CORPUS, EN_MODEL_PREFIX, vocab_size=8000)\n",
        "\n",
        "# ë¡œë“œ\n",
        "sp_ko = spm.SentencePieceProcessor()\n",
        "sp_en = spm.SentencePieceProcessor()\n",
        "sp_ko.load(KO_MODEL_PATH)\n",
        "sp_en.load(EN_MODEL_PATH)\n",
        "\n",
        "PAD_ID = 0\n",
        "BOS_ID = 1\n",
        "EOS_ID = 2\n",
        "UNK_ID = 3\n",
        "\n",
        "print(\"KO vocab size:\", sp_ko.get_piece_size())\n",
        "print(\"EN vocab size:\", sp_en.get_piece_size())\n"
      ],
      "metadata": {
        "id": "UgaMT4rwu85i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ ë°ì´í„°ì…‹ & íŒ¨ë”©\n",
        "- ì™œ Dataset / DataLoaderë¥¼ ì“°ë‚˜?  \n",
        "    - ë”¥ëŸ¬ë‹ í•™ìŠµì€ \"ë°°ì¹˜(batch)\" ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ í˜ë ¤ë³´ë‚´ëŠ” ê²Œ ê¸°ë³¸ì´ë‹¤.\n",
        "    - ë¬¸ì¥ ê¸¸ì´ëŠ” ì œê°ê°ì´ë¼ ê·¸ëŒ€ë¡œ batchë¡œ ë¬¶ìœ¼ë©´ í…ì„œ í¬ê¸°ê°€ ì•ˆ ë§ëŠ”ë‹¤.\n",
        "\n",
        "ê·¸ë˜ì„œ:\n",
        "- ê° ë¬¸ì¥ì„ id ì‹œí€€ìŠ¤ë¡œ ë°”ê¾¸ê³ \n",
        "- batchì—ì„œ ê°€ì¥ ê¸´ ê¸¸ì´ì— ë§ì¶° PAD_IDë¡œ íŒ¨ë”©í•´ì„œ\n",
        "- (batch_size, seq_len) í˜•íƒœ í…ì„œë¥¼ ë§Œë“ ë‹¤\n"
      ],
      "metadata": {
        "id": "6xe6FpWLvC4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_pair(ko: str, en: str, max_len: int):\n",
        "    \"\"\"\n",
        "    ì™œ BOS/EOSë¥¼ ë¶™ì´ë‚˜?\n",
        "    - BOS: ë””ì½”ë”ê°€ \"ì‹œì‘\"ì„ ì•Œê²Œ í•´ì£¼ëŠ” í† í°\n",
        "    - EOS: ë””ì½”ë”ê°€ \"ë\"ì„ ì•Œê²Œ í•´ì£¼ëŠ” í† í°\n",
        "    \"\"\"\n",
        "    ko_ids = [BOS_ID] + sp_ko.encode_as_ids(ko) + [EOS_ID]\n",
        "    en_ids = [BOS_ID] + sp_en.encode_as_ids(en) + [EOS_ID]\n",
        "\n",
        "    # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°(í•™ìŠµ ì•ˆì •ì„±)\n",
        "    ko_ids = ko_ids[:max_len]\n",
        "    en_ids = en_ids[:max_len]\n",
        "\n",
        "    return ko_ids, en_ids\n",
        "\n",
        "# max_lenì„ ë°ì´í„°ì—ì„œ ëŒ€ì¶© ì •í•´ì£¼ë©´ (ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸¸ê±°ë‚˜) í•™ìŠµì´ í”ë“¤ë¦´ ìˆ˜ ìˆìŒ\n",
        "# ì—¬ê¸°ì„œëŠ” ì›ë³¸ ë…¸íŠ¸ë¶ì˜ íë¦„ì²˜ëŸ¼ \"ì ë‹¹í•œ ìƒìˆ˜\"ë¡œ ë‘”ë‹¤.\n",
        "MAX_LEN = 60\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs: List[Tuple[str, str]]):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ko, en = self.pairs[idx]\n",
        "        src_ids, tgt_ids = encode_pair(ko, en, MAX_LEN)\n",
        "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: [(src_tensor, tgt_tensor), (src_tensor, tgt_tensor), ...]\n",
        "\n",
        "    ì™œ ì—¬ê¸°ì„œ íŒ¨ë”©ì„ í•˜ë‚˜?\n",
        "    - DataLoaderê°€ batchë¥¼ ë§Œë“¤ ë•Œ ê¸¸ì´ê°€ ë‹¤ë¥¸ í…ì„œëŠ” stackì´ ì•ˆ ë¨\n",
        "    - ê·¸ë˜ì„œ batch ë‚´ë¶€ ìµœëŒ€ ê¸¸ì´ì— ë§ì¶° PADë¡œ ì±„ì›Œì„œ stack ê°€ëŠ¥í•˜ê²Œ í•¨\n",
        "    \"\"\"\n",
        "    src_list, tgt_list = zip(*batch)\n",
        "\n",
        "    src_lens = torch.tensor([len(x) for x in src_list], dtype=torch.long)\n",
        "    tgt_lens = torch.tensor([len(x) for x in tgt_list], dtype=torch.long)\n",
        "\n",
        "    src_max = max(src_lens).item()\n",
        "    tgt_max = max(tgt_lens).item()\n",
        "\n",
        "    def pad_to(x, max_len):\n",
        "        pad_len = max_len - len(x)\n",
        "        if pad_len <= 0:\n",
        "            return x\n",
        "        return torch.cat([x, torch.full((pad_len,), PAD_ID, dtype=torch.long)])\n",
        "\n",
        "    src_padded = torch.stack([pad_to(x, src_max) for x in src_list], dim=0)\n",
        "    tgt_padded = torch.stack([pad_to(x, tgt_max) for x in tgt_list], dim=0)\n",
        "\n",
        "    return src_padded, src_lens, tgt_padded, tgt_lens\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(TranslationDataset(train_pairs), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(TranslationDataset(valid_pairs), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "print(\"src:\", batch[0].shape, \"src_lens:\", batch[1].shape)\n",
        "print(\"tgt:\", batch[2].shape, \"tgt_lens:\", batch[3].shape)\n"
      ],
      "metadata": {
        "id": "mIjMuKIHvPjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â—»ï¸ Attention ëª¨ë¸ ì •ì˜\n",
        "- ê¸°ë³¸ Seq2SeqëŠ” Encoderê°€ ë§ˆì§€ë§‰ hidden í•˜ë‚˜ë¡œ ëª¨ë“  ì •ë³´ë¥¼ ì••ì¶•í•´ì•¼ í•´ì„œ,\n",
        "ë¬¸ì¥ì´ ê¸¸ì–´ì§€ë©´ ë²ˆì—­ í’ˆì§ˆì´ ë–¨ì–´ì§€ê¸° ì‰½ë‹¤.\n",
        "\n",
        "Bahdanau Attentionì€:\n",
        "- ë””ì½”ë”ê°€ ë§¤ íƒ€ì„ìŠ¤í…ë§ˆë‹¤\n",
        "- encoder output ì „ì²´ë¥¼ ë³´ê³ \n",
        "- \"ì§€ê¸ˆ ì¶œë ¥í•  ë‹¨ì–´ì— ì¤‘ìš”í•œ ì…ë ¥ ìœ„ì¹˜\"ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ë½‘ëŠ”ë‹¤.\n",
        "\n",
        "ì¦‰, ë””ì½”ë”ê°€ \"í•„ìš”í•  ë•Œë§ˆë‹¤\" ì…ë ¥ ë¬¸ì¥ì„ ë‹¤ì‹œ ì°¸ì¡°í•˜ëŠ” êµ¬ì¡°\n"
      ],
      "metadata": {
        "id": "WpiK-7d1vT1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸Encoder / Attention / Decoder / Seq2Seq"
      ],
      "metadata": {
        "id": "b3J0CqIIvdNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBiGRU(nn.Module):\n",
        "    \"\"\"\n",
        "    BiGRU(ì–‘ë°©í–¥ GRU)ë¥¼ ì“°ëŠ” ì´ìœ (WHY):\n",
        "    - forward ë°©í–¥ë§Œ ë³´ë©´ \"ê³¼ê±°\"ë§Œ ì°¸ê³ \n",
        "    - backwardê¹Œì§€ ë³´ë©´ \"ë¯¸ë˜ ë¬¸ë§¥\"ë„ ê°™ì´ ë°˜ì˜\n",
        "    - ë²ˆì—­ì—ì„œëŠ” ì…ë ¥ ë¬¸ì¥ ì „ì²´ ë¬¸ë§¥ì´ ì¤‘ìš”í•´ì„œ Biê°€ ì¢…ì¢… ìœ ë¦¬\n",
        "\n",
        "    ë¬¸ë²• í¬ì¸íŠ¸:\n",
        "    - nn.Module: PyTorch ëª¨ë¸ì˜ ê¸°ë³¸ í‹€\n",
        "    - super().__init__(): ë¶€ëª¨ ì´ˆê¸°í™” í˜¸ì¶œ(íŒŒì´ì¬ OOP ê¸°ë³¸)\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_ID)\n",
        "        self.gru = nn.GRU(\n",
        "            embed_dim, hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "    def forward(self, src, src_lens):\n",
        "        # src: (B, L)\n",
        "        emb = self.embedding(src)  # (B, L, E)\n",
        "\n",
        "        # pack: íŒ¨ë”© êµ¬ê°„ì€ RNNì´ í•™ìŠµ/ê³„ì‚°í•˜ì§€ ì•Šê²Œ í•˜ëŠ” í…Œí¬ë‹‰(WHY: íš¨ìœ¨ + ì„±ëŠ¥)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, src_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, hidden = self.gru(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)  # (B, L, 2H)\n",
        "\n",
        "        # hidden: (num_layers*2, B, H)  -> ì–‘ë°©í–¥ì´ë¼ *2\n",
        "        return out, hidden\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    score(h_t, enc_out_s)ë¥¼ êµ¬í•´ì„œ softmaxë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë§Œë“  ë’¤,\n",
        "    enc_outì˜ ê°€ì¤‘í•©(context vector)ì„ ë§Œë“ ë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, enc_dim, dec_dim, attn_dim):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(enc_dim, attn_dim, bias=False)\n",
        "        self.U = nn.Linear(dec_dim, attn_dim, bias=False)\n",
        "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs, src_mask):\n",
        "        \"\"\"\n",
        "        decoder_hidden: (B, dec_dim)\n",
        "        encoder_outputs: (B, L, enc_dim)\n",
        "        src_mask: (B, L)  -> PADê°€ ì•„ë‹Œ ìœ„ì¹˜ True/False\n",
        "        \"\"\"\n",
        "        # (B, L, attn_dim)\n",
        "        score = self.v(torch.tanh(self.W(encoder_outputs) + self.U(decoder_hidden).unsqueeze(1))).squeeze(-1)\n",
        "        score = score.masked_fill(~src_mask, -1e9)  # PADëŠ” ê±°ì˜ 0í™•ë¥ ë¡œ ë§Œë“¤ê¸°\n",
        "        attn_weights = torch.softmax(score, dim=1)  # (B, L)\n",
        "\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (B, enc_dim)\n",
        "        return context, attn_weights\n",
        "\n",
        "class AttnDecoderGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, enc_dim, dec_dim, attn_dim, num_layers=1, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_ID)\n",
        "        self.attn = BahdanauAttention(enc_dim, dec_dim, attn_dim)\n",
        "\n",
        "        # ë””ì½”ë” ì…ë ¥ = (í˜„ì¬ ì…ë ¥ í† í° ì„ë² ë”© + context)\n",
        "        self.gru = nn.GRU(embed_dim + enc_dim, dec_dim, num_layers=num_layers, batch_first=True,\n",
        "                          dropout=dropout if num_layers > 1 else 0.0)\n",
        "\n",
        "        self.fc_out = nn.Linear(dec_dim + enc_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_tokens, decoder_hidden, encoder_outputs, src_mask):\n",
        "        \"\"\"\n",
        "        input_tokens: (B,) - í˜„ì¬ íƒ€ì„ìŠ¤í…ì˜ ì…ë ¥ í† í° id\n",
        "        decoder_hidden: (num_layers, B, dec_dim)\n",
        "        \"\"\"\n",
        "        emb = self.dropout(self.embedding(input_tokens)).unsqueeze(1)  # (B,1,E)\n",
        "\n",
        "        # attentionì€ ë³´í†µ \"ë§ˆì§€ë§‰ ë ˆì´ì–´ hidden\"ì„ ì‚¬ìš©\n",
        "        dec_h_last = decoder_hidden[-1]  # (B, dec_dim)\n",
        "        context, attn_w = self.attn(dec_h_last, encoder_outputs, src_mask)  # (B, enc_dim)\n",
        "\n",
        "        rnn_input = torch.cat([emb, context.unsqueeze(1)], dim=-1)  # (B,1,E+enc_dim)\n",
        "        out, new_hidden = self.gru(rnn_input, decoder_hidden)       # out: (B,1,dec_dim)\n",
        "\n",
        "        out = out.squeeze(1)  # (B, dec_dim)\n",
        "        logits = self.fc_out(torch.cat([out, context], dim=-1))  # (B, vocab)\n",
        "        return logits, new_hidden, attn_w\n",
        "\n",
        "class Seq2SeqAttn(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n",
        "        \"\"\"\n",
        "        teacher_forcing_ratioë¥¼ ì“°ëŠ” ì´ìœ (WHY):\n",
        "        - í•™ìŠµ ì´ˆë°˜ì— ëª¨ë¸ì´ ì˜ˆì¸¡ì„ ì˜ ëª»í•˜ë‹ˆê¹Œ,\n",
        "          ì •ë‹µ í† í°ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ë©´ í•™ìŠµì´ ì•ˆì •ì \n",
        "        - ë‹¤ë§Œ ë„ˆë¬´ ë§ì´ ì“°ë©´ ì‹¤ì œ ì¶”ë¡ (ì •ë‹µì´ ì—†ëŠ” ìƒí™©)ì— ì•½í•´ì§ˆ ìˆ˜ ìˆìŒ\n",
        "        \"\"\"\n",
        "        B = src.size(0)\n",
        "        T = tgt.size(1)\n",
        "        vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "        src_mask = (src != PAD_ID)  # (B, L)\n",
        "\n",
        "        enc_out, enc_hidden = self.encoder(src, src_lens)\n",
        "\n",
        "        # BiGRU hiddenì„ ë””ì½”ë” ì°¨ì›ìœ¼ë¡œ ë§ì¶°ì£¼ëŠ” ë°©ì‹ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆìŒ.\n",
        "        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ \"ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ forward/backwardë¥¼ concat í›„ ì„ í˜• ë³€í™˜\" ê°™ì€ ë°©ë²•ì„ ì“°ê¸°ë„ í•œë‹¤.\n",
        "        # ì›ë³¸ ë…¸íŠ¸ë¶ íë¦„ì„ ìµœëŒ€í•œ ë‹¨ìˆœí™”í•´ì„œ, ë””ì½”ë” ì´ˆê¸° hiddenì„ 0ìœ¼ë¡œ ì‹œì‘(ê°€ì¥ ì•ˆì „í•œ ë² ì´ìŠ¤ë¼ì¸)í•œë‹¤.\n",
        "        dec_hidden = torch.zeros(1, B, 256, device=src.device)\n",
        "\n",
        "        outputs = torch.zeros(B, T, vocab_size, device=src.device)\n",
        "\n",
        "        input_tok = tgt[:, 0]  # BOS\n",
        "\n",
        "        for t in range(1, T):\n",
        "            logits, dec_hidden, _ = self.decoder(input_tok, dec_hidden, enc_out, src_mask)\n",
        "            outputs[:, t] = logits\n",
        "\n",
        "            use_tf = random.random() < teacher_forcing_ratio\n",
        "            top1 = logits.argmax(dim=-1)  # (B,)\n",
        "            input_tok = tgt[:, t] if use_tf else top1\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "h566zDdcvbeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸í•™ìŠµ/ê²€ì¦ ë£¨í”„\n",
        "- CrossEntropyLossëŠ” \"ë¶„ë¥˜\" ì†ì‹¤ì´ë‹¤.\n",
        "- ë²ˆì—­ì€ ë§¤ íƒ€ì„ìŠ¤í…ë§ˆë‹¤ ë‹¤ìŒ í† í°ì„ \"ë¶„ë¥˜\"í•˜ëŠ” ë¬¸ì œë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤.\n",
        "  (ì˜ˆ: \"ë‹¤ìŒ í† í°ì´ vocabì—ì„œ ë¬´ì—‡ì¸ê°€?\")\n",
        "\n",
        "ê·¸ë˜ì„œ:\n",
        "- decoder output logits: (B, T, vocab)\n",
        "- target: (B, T)\n",
        "ë¥¼\n",
        "- (B*T, vocab) vs (B*T)\n",
        "ë¡œ í¼ì³ì„œ(loss ê³„ì‚°ì„ ì‰½ê²Œ) í•™ìŠµí•œë‹¤.\n"
      ],
      "metadata": {
        "id": "Z0dOz9MIvlMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸train/eval í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "bV4yrR4Rvr6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, teacher_forcing_ratio=0.5):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for src, src_lens, tgt, tgt_lens in loader:\n",
        "        src, src_lens, tgt = src.to(device), src_lens.to(device), tgt.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(src, src_lens, tgt, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "        # out: (B, T, vocab)\n",
        "\n",
        "        # íƒ€ì„ìŠ¤í… 0(BOS)ì€ ì˜ˆì¸¡ ëŒ€ìƒì—ì„œ ì œì™¸í•˜ëŠ” ê²½ìš°ê°€ ì¼ë°˜ì \n",
        "        out = out[:, 1:].contiguous()\n",
        "        tgt_y = tgt[:, 1:].contiguous()\n",
        "\n",
        "        loss = criterion(out.view(-1, out.size(-1)), tgt_y.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        # ê¸°ìš¸ê¸° í­ë°œ ë°©ì§€(WHY: RNNì€ í­ë°œì´ ì˜ ì¼ì–´ë‚¨)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for src, src_lens, tgt, tgt_lens in loader:\n",
        "        src, src_lens, tgt = src.to(device), src_lens.to(device), tgt.to(device)\n",
        "\n",
        "        out = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)\n",
        "        out = out[:, 1:].contiguous()\n",
        "        tgt_y = tgt[:, 1:].contiguous()\n",
        "\n",
        "        loss = criterion(out.view(-1, out.size(-1)), tgt_y.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ],
      "metadata": {
        "id": "M_119sWevwHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸í•™ìŠµ ì‹¤í–‰ + best ì €ì¥"
      ],
      "metadata": {
        "id": "_TxuOG2ovzCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì›ë³¸ ë…¸íŠ¸ë¶ í•˜ì´í¼íŒŒë¼ë¯¸í„°(ë„¤ íŒŒì¼ ê¸°ì¤€)\n",
        "BATCH_SIZE = 64\n",
        "embed_dim = 256\n",
        "hidden_dim = 256\n",
        "dropout = 0.1\n",
        "lr = 0.001\n",
        "num_epochs = 30\n",
        "\n",
        "encoder = EncoderBiGRU(vocab_size=sp_ko.get_piece_size(), embed_dim=embed_dim, hidden_dim=hidden_dim, dropout=dropout).to(device)\n",
        "decoder = AttnDecoderGRU(vocab_size=sp_en.get_piece_size(), embed_dim=embed_dim,\n",
        "                         enc_dim=hidden_dim*2, dec_dim=hidden_dim, attn_dim=hidden_dim,\n",
        "                         dropout=dropout).to(device)\n",
        "\n",
        "model = Seq2SeqAttn(encoder, decoder).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "BEST_PATH = os.path.join(DATA_DIR, \"best_seq2seq_attn.pt\")\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, teacher_forcing_ratio=0.5)\n",
        "    val_loss = eval_epoch(model, valid_loader, criterion)\n",
        "\n",
        "    saved = \"\"\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), BEST_PATH)\n",
        "        saved = \" | Saved\"\n",
        "\n",
        "    print(f\"Epoch: {epoch}/{num_epochs} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}{saved}\")\n",
        "\n",
        "print(\"best_val_loss:\", best_val)\n",
        "print(\"best_model_path:\", BEST_PATH)\n"
      ],
      "metadata": {
        "id": "S8HB52Obv0IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸ì¶”ë¡ (ë²ˆì—­)í•¨ìˆ˜\n",
        "- í•™ìŠµ ë•ŒëŠ” ì •ë‹µ í† í°ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” Teacher Forcingì„ ì¼ì§€ë§Œ,\n",
        "- ì‹¤ì œ ë²ˆì—­(ì¶”ë¡ )ì—ì„œëŠ” ì •ë‹µì´ ì—†ìœ¼ë¯€ë¡œ \"ë‚´ê°€ ì˜ˆì¸¡í•œ í† í°\"ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.\n",
        "\n",
        "- ì´ë•Œ ê¸°ë³¸ì€ greedy decoding(argmax)ì¸ë°, BLEUë¥¼ ì˜¬ë¦¬ë ¤ë©´ beam searchë¡œ ë°”ê¾¸ëŠ” ê²½ìš°ê°€ ë§ë‹¤.\n"
      ],
      "metadata": {
        "id": "c51H4Mg3v28z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸translate í•¨ìˆ˜ + ìƒ˜í”Œ ì¶œë ¥"
      ],
      "metadata": {
        "id": "D2x1bibQwB6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def translate(model, ko_sentence: str, max_len: int = 60):\n",
        "    model.eval()\n",
        "\n",
        "    src_ids, _ = encode_pair(ko_sentence, \"dummy\", max_len)\n",
        "    src = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)  # (1, L)\n",
        "    src_lens = torch.tensor([len(src_ids)], dtype=torch.long).to(device)\n",
        "\n",
        "    src_mask = (src != PAD_ID)\n",
        "\n",
        "    enc_out, _ = model.encoder(src, src_lens)\n",
        "\n",
        "    # ë””ì½”ë” ì´ˆê¸° hidden(ì—¬ê¸°ì„  0 ì‹œì‘ ë² ì´ìŠ¤ë¼ì¸)\n",
        "    dec_hidden = torch.zeros(1, 1, 256, device=device)\n",
        "\n",
        "    input_tok = torch.tensor([BOS_ID], device=device)\n",
        "\n",
        "    out_ids = []\n",
        "    for _ in range(max_len):\n",
        "        logits, dec_hidden, _ = model.decoder(input_tok, dec_hidden, enc_out, src_mask)\n",
        "        top1 = logits.argmax(dim=-1).item()\n",
        "\n",
        "        if top1 == EOS_ID:\n",
        "            break\n",
        "        out_ids.append(top1)\n",
        "        input_tok = torch.tensor([top1], device=device)\n",
        "\n",
        "    return sp_en.decode_ids(out_ids)\n",
        "\n",
        "# best ëª¨ë¸ ë¡œë“œ í›„ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸\n",
        "model.load_state_dict(torch.load(BEST_PATH, map_location=device))\n",
        "\n",
        "for i in range(5):\n",
        "    ko, en = random.choice(valid_pairs)\n",
        "    pred = translate(model, ko)\n",
        "    print(f\"\\n[ì…ë ¥] {ko}\")\n",
        "    print(f\"[ì •ë‹µ] {en}\")\n",
        "    print(f\"[ì˜ˆì¸¡] {pred}\")\n"
      ],
      "metadata": {
        "id": "6QIhjfzEwBSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–«ï¸BLEU ê³„ì‚°"
      ],
      "metadata": {
        "id": "0vpJ1_4PwJNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_bleu(model, pairs, num_samples=1000):\n",
        "    \"\"\"\n",
        "    sacrebleuë¥¼ ì‚¬ìš©í•˜ë©´ í† í°í™”/ì •ê·œí™”ê°€ ë¹„êµì  ì•ˆì •ì ì´ë¼ ì‹¤í—˜ ë¹„êµê°€ í¸í•˜ë‹¤.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    samples = random.sample(pairs, min(num_samples, len(pairs)))\n",
        "\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    for ko, en in samples:\n",
        "        pred = translate(model, ko)\n",
        "        preds.append(pred)\n",
        "        refs.append(en)\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(preds, [refs]).score / 100.0\n",
        "    return bleu\n",
        "\n",
        "bleu = compute_bleu(model, valid_pairs, num_samples=1000)\n",
        "print(f\"ìµœì¢… BLEU ì ìˆ˜: {bleu:.4f}\")\n"
      ],
      "metadata": {
        "id": "cQE9DUeRwLya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸŸ¨ ê²°ë¡  ë° íšŒê³  (ì‹¤í—˜ ê²°ê³¼ ì¢…í•©)\n",
        "\n",
        "ì´ë²ˆ ë¯¸ì…˜ì€ í•œêµ­ì–´ â†’ ì˜ì–´ ê¸°ê³„ë²ˆì—­ì„ ëª©í‘œë¡œ, Seq2Seq ê³„ì—´ ëª¨ë¸ì„ ë‹¨ê³„ì ìœ¼ë¡œ ê°œì„ í•˜ë©´ì„œ\n",
        "(1) í•™ìŠµì€ ë˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ”ë° ì‹¤ì œ ë²ˆì—­ í’ˆì§ˆì€ ì™œ ì•ˆ ë‚˜ì˜¤ëŠ”ì§€ë¥¼ ì§ì ‘ í™•ì¸í•œ í”„ë¡œì íŠ¸ì˜€ë‹¤.\n",
        "\n",
        "í•µì‹¬ì€:\n",
        "- ëª¨ë¸ êµ¬ì¡°(Seq2Seq vs Attention)ë„ ì¤‘ìš”í•˜ì§€ë§Œ,\n",
        "- ì‹¤ì œ ì„±ëŠ¥ì€ ë°ì´í„° ì „ì²˜ë¦¬ + í† í¬ë‚˜ì´ì§•(ì–´íœ˜ ë¬¸ì œ) + í•™ìŠµ/ì¶”ë¡  ë°©ì‹(Teacher Forcing, decoding)ì´ í›¨ì”¬ í¬ê²Œ ì¢Œìš°í–ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "### 1) ì‹¤í—˜ 1: ê¸°ë³¸ Seq2Seq (ë‹¨ì–´ ê¸°ë°˜ í† í¬ë‚˜ì´ì €)\n",
        "- í•™ìŠµ ë¡œê·¸ìƒìœ¼ë¡œëŠ” Lossê°€ ê³„ì† ë‚´ë ¤ê°€ë©° í•™ìŠµì´ â€œë˜ëŠ” ê²ƒì²˜ëŸ¼â€ ë³´ì˜€ë‹¤.\n",
        "  - ì˜ˆ: 30 epoch ê¸°ì¤€ Train Lossê°€ ì•½ 0.76 â†’ 0.27 ìˆ˜ì¤€ê¹Œì§€ ê°ì†Œ\n",
        "- í•˜ì§€ë§Œ ì‹¤ì œ ë²ˆì—­ ê²°ê³¼(ì •ì„± í‰ê°€)ëŠ” ë‹¤ìŒ ë¬¸ì œê°€ ë°˜ë³µëë‹¤.\n",
        "  - UNK(â‡) í† í°ì´ ìì£¼ ë“±ì¥ â†’ ë‹¨ì–´ ê¸°ë°˜ vocabì´ ì»¤ë²„ ëª» í•˜ëŠ” ë‹¨ì–´ê°€ ë§ìŒ\n",
        "  - ë¬¸ì¥ êµ¬ì¡°ê°€ ë¬´ë„ˆì§€ê³ , ì˜ë¯¸ê°€ ë§ì§€ ì•ŠëŠ” ì¶œë ¥ì´ ë‚˜ì˜´\n",
        "  - í•™ìŠµ ë°ì´í„°ì˜ íŠ¹ìˆ˜ë¬¸ì/ë”°ì˜´í‘œ/ê¸°í˜¸ê°€ ë‚¨ì•„ìˆìœ¼ë©´ ì¶œë ¥ì´ ë” í”ë“¤ë¦¼\n",
        "\n",
        "ì •ë¦¬:\n",
        "- Lossê°€ ë‚´ë ¤ê°„ë‹¤ = ë²ˆì—­ì´ ì˜ ëœë‹¤ê°€ ì•„ë‹ˆì—ˆë‹¤.\n",
        "- íŠ¹íˆ ë‹¨ì–´ ê¸°ë°˜ í† í¬ë‚˜ì´ì €ëŠ” OOV(ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´) ë¬¸ì œ ë•Œë¬¸ì— ë²ˆì—­ì—ì„œ ë°”ë¡œ í•œê³„ê°€ ë“œëŸ¬ë‚¬ë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "### 2) ì‹¤í—˜ 2: Seq2Seq + Attention (ë‹¨ì–´ ê¸°ë°˜ í† í¬ë‚˜ì´ì € ìœ ì§€)\n",
        "- Attentionì„ ë¶™ì´ë©´ ì´ë¡ ì ìœ¼ë¡œ \"ì–´ë–¤ ì…ë ¥ ë‹¨ì–´ë¥¼ ì°¸ê³ í•´ì•¼ í•˜ëŠ”ì§€\"ë¥¼ ë” ì˜ ë°°ìš°ëŠ” êµ¬ì¡°ë‹¤.\n",
        "- ì‹¤ì œë¡œ LossëŠ” ë” ì¢‹ì•„ì¡Œë‹¤.\n",
        "  - ì˜ˆ: 30 epoch ê¸°ì¤€ Train Lossê°€ ëŒ€ëµ 0.74 â†’ 0.21 ìˆ˜ì¤€ê¹Œì§€ ê°ì†Œ\n",
        "- í•˜ì§€ë§Œ ë²ˆì—­ ì¶œë ¥ì€ ê¸°ëŒ€ë§Œí¼ ì¢‹ì•„ì§€ì§€ ì•Šì•˜ë‹¤.\n",
        "  - ê¸°ë³¸ í† í¬ë‚˜ì´ì €/ì „ì²˜ë¦¬ì˜ í•œê³„ê°€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆì–´ì„œ,\n",
        "  - Attentionì´ ìˆì–´ë„ â€œì œëŒ€ë¡œ ëœ ë‹¨ì–´ë¥¼ ëª» ì½ê³ (UNK), ì œëŒ€ë¡œ ëœ ë‹¨ì–´ë¥¼ ëª» ë‚´ë³´ë‚´ëŠ”â€ ë¬¸ì œê°€ ìœ ì§€ëë‹¤.\n",
        "- ì´ êµ¬ê°„ì—ì„œ BLEU í‰ê°€ê°€ ì‚¬ì‹¤ìƒ ì˜ë¯¸ê°€ ì—†ì„ ì •ë„ë¡œ ë‚®ê²Œ ë‚˜ì™”ë‹¤.\n",
        "  - ì˜ˆ: BLEU score: 0.0000 ì¶œë ¥ì´ í™•ì¸ë¨\n",
        "\n",
        "ì •ë¦¬:\n",
        "- Attentionì€ ì—”ì§„ ì„±ëŠ¥ì„ ì˜¬ë¦¬ëŠ” ì—…ê·¸ë ˆì´ë“œì— ê°€ê¹ë‹¤.\n",
        "- ê·¸ëŸ°ë° ë°ì´í„°ì™€ í† í¬ë‚˜ì´ì§•/ì „ì²˜ë¦¬ê°€ ì—‰ë§ì´ë©´ ì—”ì§„ë§Œ ì¢‹ì•„ì ¸ì„œëŠ” ê²°ê³¼ê°€ ì•ˆ ë‚˜ì˜¨ë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "### 3) ì‹¤í—˜ 3: SentencePiece(Subword) + í•™ìŠµ ì•ˆì •í™”(Teacher Forcing ì¡°ì ˆ) + Beam Search\n",
        "ì—¬ê¸°ì„œë¶€í„° â€œë²ˆì—­ ëª¨ë¸ë‹µê²Œâ€ ì„±ëŠ¥ì´ ì˜¬ë¼ê°€ê¸° ì‹œì‘í–ˆë‹¤.\n",
        "\n",
        "ì ìš©í•œ ê°œì„  í¬ì¸íŠ¸:\n",
        "- SentencePiece(Subword) ê¸°ë°˜ í† í¬ë‚˜ì´ì €\n",
        "  - ë‹¨ì–´ ë‹¨ìœ„ê°€ ì•„ë‹ˆë¼ ì¡°ê°(subword) ë‹¨ìœ„ë¡œ ì²˜ë¦¬ â†’ OOV/UNK ê¸‰ê°\n",
        "- Teacher Forcing ë¹„ìœ¨ì„ ì ì§„ì ìœ¼ë¡œ ê°ì†Œ\n",
        "  - ì´ˆë°˜ì—” ì •ë‹µì„ ë§ì´ ë³´ì—¬ì£¼ë©° ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ê³ ,\n",
        "  - í›„ë°˜ì—” ì •ë‹µ ì˜ì¡´ì„ ì¤„ì—¬ì„œ \"ì‹¤ì „(ì¶”ë¡ )\"ì— ì ì‘ì‹œí‚¤ëŠ” ë°©ì‹\n",
        "  - ì‹¤ì œ ë¡œê·¸ì—ì„œë„ TFê°€ 1.00 â†’ 0.30ê¹Œì§€ ë‚´ë ¤ê°€ë©° í•™ìŠµë¨\n",
        "- Beam Search ë””ì½”ë”©\n",
        "  - greedy(í•œ ë²ˆì— ìµœê³ ë§Œ ê³ ë¥´ê¸°)ë³´ë‹¤ ë¬¸ì¥ í’ˆì§ˆì´ ì¢‹ì•„ì§ˆ ê°€ëŠ¥ì„±ì´ í¼\n",
        "\n",
        "ê²°ê³¼(ì •ëŸ‰):\n",
        "- í•™ìŠµ ë¡œê·¸ ì˜ˆì‹œ:\n",
        "  - Epoch 1: Train Loss 5.509, Val Loss 6.000\n",
        "  - Epoch 30: Train Loss 2.721, Val Loss 5.267\n",
        "- BLEU ì ìˆ˜(ê²€ì¦ì…‹):\n",
        "  - Validation BLEU: 0.1298\n",
        "\n",
        "ì •ë¦¬:\n",
        "- ì´ ì‹¤í—˜ì—ì„œ â€œì´ì œì•¼ ë²ˆì—­ì´ ì„±ëŠ¥ìœ¼ë¡œ ì¸¡ì • ê°€ëŠ¥í•œ ìˆ˜ì¤€â€ê¹Œì§€ ì˜¬ë¼ì™”ë‹¤.\n",
        "- íŠ¹íˆ BLEUê°€ 0ì—ì„œ **0.1298ë¡œ ì˜¬ë¼ê°„ ë³€í™” ìì²´ê°€** í† í¬ë‚˜ì´ì§•/ì¶”ë¡  ë°©ì‹ì˜ ì˜í–¥ë ¥ì„ ë³´ì—¬ì¤€ë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ì´ë²ˆ ë¯¸ì…˜ì—ì„œ ì–»ì€ êµí›ˆ\n",
        "\n",
        "1) í† í¬ë‚˜ì´ì €/ì–´íœ˜ê°€ ì„±ëŠ¥ì˜ ìƒí•œì„ ì„ ê²°ì •í•œë‹¤\n",
        "- ë‹¨ì–´ ê¸°ë°˜ vocabì€ í˜„ì‹¤ ë°ì´í„°ì—ì„œ OOVê°€ ë„ˆë¬´ ë§ì´ ë°œìƒí•œë‹¤.\n",
        "- ë²ˆì—­ì—ì„œ OOVëŠ” ê³§ë°”ë¡œ UNK ë˜ëŠ” ì˜ë¯¸ ë¶•ê´´ë¡œ ì´ì–´ì§„ë‹¤.\n",
        "- Subword(SentencePiece)ëŠ” ì´ ë¬¸ì œë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ì™„í™”í•œë‹¤.\n",
        "\n",
        "2) LossëŠ” \"í•™ìŠµ ì¤‘ ì„±ëŠ¥\"ì´ì§€ ë²ˆì—­ í’ˆì§ˆì´ ì•„ë‹ˆë‹¤\n",
        "- Teacher Forcing í™˜ê²½ì—ì„œ lossê°€ ë‚´ë ¤ê°€ë„,\n",
        "- ì‹¤ì œ ì¶”ë¡ (ëª¨ë¸ì´ ìê¸° ì¶œë ¥ì„ ë‹¤ì‹œ ì…ë ¥ìœ¼ë¡œ ì“°ëŠ” ìƒí™©)ì—ì„œëŠ” í’ˆì§ˆì´ ê¸‰ë½í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "3) í‰ê°€ëŠ” ì¶”ë¡  íŒŒì´í”„ë¼ì¸ê¹Œì§€ í¬í•¨í•´ì„œ ë´ì•¼ í•œë‹¤\n",
        "- BLEUëŠ” ë‹¨ìˆœíˆ ëª¨ë¸ë§Œì˜ ì ìˆ˜ê°€ ì•„ë‹ˆë¼,\n",
        "- ì „ì²˜ë¦¬/ë””ì½”ë”©/í›„ì²˜ë¦¬ê¹Œì§€ í¬í•¨í•œ ì „ì²´ ë²ˆì—­ ì‹œìŠ¤í…œì˜ ì ìˆ˜ë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ë‹¤ìŒ ê°œì„  ë°©í–¥ (ì‹¤ì œë¡œ ì ìˆ˜/í’ˆì§ˆ ì˜¬ë¦¬ëŠ” ìª½)\n",
        "\n",
        "- ì „ì²˜ë¦¬ ê°•í™”:\n",
        "  - ë”°ì˜´í‘œ/íŠ¹ìˆ˜ë¬¸ì/ë¶ˆí•„ìš” ê¸°í˜¸ ì •ë¦¬\n",
        "  - í•œ/ì˜ ë¬¸ì¥ í˜ì–´ì—ì„œ ê¹¨ì§„ ìƒ˜í”Œ ì œê±°\n",
        "- í•™ìŠµ ì•ˆì •í™”:\n",
        "  - LR scheduler, gradient clipping, early stopping\n",
        "  - label smoothing(ì„ íƒ)\n",
        "- ì¶”ë¡  ê°œì„ :\n",
        "  - Beam size íŠœë‹, length penalty ì ìš©\n",
        "  - ë°˜ë³µ ì¶œë ¥ ë°©ì§€(no-repeat ngram ë“±)\n",
        "- í‰ê°€ ê°•í™”:\n",
        "  - SacreBLEUë¡œ ì¬í˜„ ê°€ëŠ¥í•œ BLEU ê³„ì‚°\n",
        "  - ëœë¤ ìƒ˜í”Œ ì •ì„±í‰ê°€(â€œì˜ë¯¸ ë³´ì¡´/ë¬¸ë²•/ìì—°ìŠ¤ëŸ¬ì›€â€) ì²´í¬ë¦¬ìŠ¤íŠ¸í™”\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_1dK0OrpwO17"
      }
    }
  ]
}